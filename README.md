You are asked to work on a time series forecasting project using advanced deep learning techniques. First, you need to create (or find) a dataset with at least five different but related features that clearly show patterns like trends, seasonal changes, and random noise. Then, using tools like PyTorch or TensorFlow, you will build a Transformer model specifically designed for time series data, paying careful attention to how you encode the sequence information so the model understands time-based relationships.

Next, you’ll train your model—making sure to use smart techniques like adjusting the learning rate and clipping gradients so the training is stable and efficient. You’ll explore different options for how long the input sequences should be and how many attention heads (parts of the model that focus on different patterns) to use, all while tuning these settings to get the best results.

Once your model is trained, you’ll compare how well it performs against classic methods (like SARIMA or LSTM) using key metrics for forecasting accuracy. Finally, you’ll document your process, explaining your design choices, how well the model trained, and how you decided on the best settings.

Your deliverables are clear:

Share the complete Python code for your Transformer and training steps.

Write a report about how you built or chose your data, what changes you made to the model for time series forecasting, and how it compares with older models.

Summarize which settings (hyperparameters) worked best, and explain why you chose them.

This project pushes you to combine hands-on coding with thoughtful analysis—a chance to showcase both your technical and storytelling skills in a real-world machine learning pipeline.
